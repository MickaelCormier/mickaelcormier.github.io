---
title: "Interactive Labeling for Human Pose Estimation in Surveillance Videos"
collection: publications
type: "Proceedings"
permalink: publications/2021-10_Interactive_Labeling_for_Human_Pose_Estimation_in_Surveillance_Videos
venue: "Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops"
authors: "Mickael Cormier, Fabian Röpke, Thomas Golda, Jürgen Beyerer"
year: 2021
date: 2021-10-26
tags:
  - iccv
  - annotation
  - human pose estimation
  - data generation
  - surveillance
data:
bibtex: 2021-10_Interactive_Labeling_for_Human_Pose_Estimation_in_Surveillance_Videos.bib
pdf: https://doi.org/10.1007/978-3-030-66823-5_41
poster:
slides:
code:
excerpt: "Automatically detecting and estimating the movement of persons in real-world uncooperative scenarios is very challenging in great part due to limited and unreliably annotated data. For instance annotating a single human body pose for activity recognition requires ..."
img: 202110_iccv.png
---

Automatically detecting and estimating the movement of persons in real-world uncooperative scenarios is very challenging in great part due to limited and unreliably annotated data. For instance annotating a single human body pose for activity recognition requires 40-60 seconds in complex sequences, leading to long-winded and costly annotation processes. Therefore increasing the sizes of annotated datasets through crowdsourcing or automated annotation is often used at a great financial costs, without reliable validation processes and inadequate annotation tools greatly impacting the annotation quality. In this work we combine multiple techniques into a single web-based general-purpose annotation application. Pre-trained machine learning models enable annotators to interactively detect pedestrians, re-identify them throughout the sequence, estimate their poses, and correct annotation suggestions in the same interface. Annotations are then inter- and extrapolated between frames. The application is evaluated through several user studies and the results are extensively analyzed. Experiments demonstrate a 55% reduction in annotation time for less complex scenarios while simultaneously decreasing perceived annotator workload.